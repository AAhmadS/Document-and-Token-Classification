{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBs1fmh4xZC3N6xAmLhl5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAhmadS/NLP_HW4/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Natural Language Processing-Homework4**\n",
        "\n",
        "####**Students' names** :\n",
        ">Amirahmad Shafiee<br/>\n",
        ">Ali Shafiee<br/>\n",
        ">Neda Fallah<br/>\n",
        "####**Student number** : 99104027<br/>**Chosen task** : classification In this notebook we aim to do common but rather essential preprocess actions on some text chosen from the persian literature world. After doing so, an NLP task would be operated on the processed text."
      ],
      "metadata": {
        "id": "6f77_QYUoCU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers\n",
        "!pip install -qU torchtext\n",
        "!pip install -qU fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVW9dUiqqC2x",
        "outputId": "10960035-b1ca-46b6-e358-ba4c5e9f6cd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiLCZAB2qsPC",
        "outputId": "553498fa-aea8-44e6-a2c2-a566e63cd8d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3946, done.\u001b[K\n",
            "remote: Counting objects: 100% (980/980), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 3946 (delta 878), reused 839 (delta 828), pack-reused 2966\u001b[K\n",
            "Receiving objects: 100% (3946/3946), 8.25 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (2510/2510), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext.util"
      ],
      "metadata": {
        "id": "3MbF6SqdsRvL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip install fastText/.\n",
        "!cd fastText\n",
        "fasttext.util.download_model('fa', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.fa.300.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4hRGDiquyb",
        "outputId": "df1bbb93-e702-4558-abaf-956741ea7d30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./fastText\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (2.10.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4384288 sha256=21dc9db8052fec4d9a09638cc204b9da324b7ef7d72c8c350d22d896078f94ae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xy5o13wr/wheels/8b/05/af/3cfae069d904597d44b309c956601b611bdf8967bcbe968903\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "  Attempting uninstall: fasttext\n",
            "    Found existing installation: fasttext 0.9.2\n",
            "    Uninstalling fasttext-0.9.2:\n",
            "      Successfully uninstalled fasttext-0.9.2\n",
            "Successfully installed fasttext-0.9.2\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6e8tddyq1NL",
        "outputId": "6e348182-aa9a-4a30-9c43-f5217fd9150b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nlp_hw4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WTcBKFmq24T",
        "outputId": "dda2557d-cd14-45f9-c7b0-9ba54457971e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp_hw4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Essential packages"
      ],
      "metadata": {
        "id": "WVv2J05RoLoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import pad\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "%matplotlib inline\n",
        "import matplotlib.ticker as ticker\n",
        "from collections import Counter\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import resample\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "import sklearn.svm as svm\n",
        "from sklearn.model_selection import StratifiedKFold as skf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score as acs\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import roc_curve, auc,precision_recall_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import fasttext.util\n",
        "\n",
        "import itertools\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchtext\n",
        "from torchtext.vocab import Vocab\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "import nltk, re\n",
        "from nltk import word_tokenize, sent_tokenize, WhitespaceTokenizer, FreqDist, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "import copy\n",
        "import collections\n",
        "import torch"
      ],
      "metadata": {
        "id": "RH_5fv9ep_9J"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load data and analysis\n"
      ],
      "metadata": {
        "id": "2CCwlBiboO3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('food.jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "data = pd.DataFrame([])\n",
        "for json_str in json_list:\n",
        "    result = json.loads(json_str)\n",
        "    data = data.append(result,ignore_index=True)"
      ],
      "metadata": {
        "id": "MRPeM6-mqfgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().value_counts()"
      ],
      "metadata": {
        "id": "89PQN4Pymd77",
        "outputId": "96894cc6-d891-4b04-8b52-9fc4e2ad4dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review  sentiment  category  aspects\n",
              "False   False      False     False      1917\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(10)"
      ],
      "metadata": {
        "id": "q0tAUeSboJqV",
        "outputId": "810b4b85-e812-4feb-c3d0-408727a3a37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 review sentiment  \\\n",
              "1130  همه می دونن که عسل انواع مختلفی داره؛ البته با...         1   \n",
              "799   هم قیمتش نسبت ب روغن های دیگه مناسب تره هم از ...         1   \n",
              "1693       با بقیه چایی ها هیچ فرقی نداره چه طعم چه رنگ         0   \n",
              "95    وقتی دستم رسید خیلی از بیسکوبیت ها خورد و نصف ...        -2   \n",
              "1687  پولتونو تو چاه نریزید،کافئین کم،طعم ضعیف،متاسف...        -2   \n",
              "907    ریز بودن حتی تو تخفیف هم نگیرین خوشمزه نیست اسلا        -2   \n",
              "184   خیلی تند هست من که زیاد نمیتونم تو دهن ام نگه ...        -2   \n",
              "600   تکه های ماهی درشت هستند و مثل خیلی از تن ها خر...         1   \n",
              "373   برای مدرسه بچه ها مناسب است و چون ویتامینه است...         1   \n",
              "562   بطری های عالیس طوری طراحی شدند که نور به هیچ ع...         2   \n",
              "\n",
              "                        category  \\\n",
              "1130                         عسل   \n",
              "799                         روغن   \n",
              "1693                         چای   \n",
              "95                بیسکویت و ویفر   \n",
              "1687                        قهوه   \n",
              "907           تخمه و مغز طعم‌دار   \n",
              "184   آدامس و خوشبو کننده‌ی دهان   \n",
              "600                      تن ماهی   \n",
              "373                          شیر   \n",
              "562                          شیر   \n",
              "\n",
              "                                              aspects  \n",
              "1130                               {'ارزش خرید': '1'}  \n",
              "799                  {'ارزش خرید': '1', 'کیفیت': '1'}  \n",
              "1693                                     {'طعم': '0'}  \n",
              "95                                                 {}  \n",
              "1687  {'کیفیت': '-1', 'ارزش خرید': '-2', 'طعم': '-1'}  \n",
              "907                                     {'طعم': '-2'}  \n",
              "184                                     {'طعم': '-2'}  \n",
              "600                                                {}  \n",
              "373                               {'ارزش غذایی': '1'}  \n",
              "562                                {'بسته بندی': '2'}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e58b8ee9-dd67-4ff0-aa87-ca6cb9f63298\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>category</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>همه می دونن که عسل انواع مختلفی داره؛ البته با...</td>\n",
              "      <td>1</td>\n",
              "      <td>عسل</td>\n",
              "      <td>{'ارزش خرید': '1'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>هم قیمتش نسبت ب روغن های دیگه مناسب تره هم از ...</td>\n",
              "      <td>1</td>\n",
              "      <td>روغن</td>\n",
              "      <td>{'ارزش خرید': '1', 'کیفیت': '1'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1693</th>\n",
              "      <td>با بقیه چایی ها هیچ فرقی نداره چه طعم چه رنگ</td>\n",
              "      <td>0</td>\n",
              "      <td>چای</td>\n",
              "      <td>{'طعم': '0'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>وقتی دستم رسید خیلی از بیسکوبیت ها خورد و نصف ...</td>\n",
              "      <td>-2</td>\n",
              "      <td>بیسکویت و ویفر</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1687</th>\n",
              "      <td>پولتونو تو چاه نریزید،کافئین کم،طعم ضعیف،متاسف...</td>\n",
              "      <td>-2</td>\n",
              "      <td>قهوه</td>\n",
              "      <td>{'کیفیت': '-1', 'ارزش خرید': '-2', 'طعم': '-1'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>ریز بودن حتی تو تخفیف هم نگیرین خوشمزه نیست اسلا</td>\n",
              "      <td>-2</td>\n",
              "      <td>تخمه و مغز طعم‌دار</td>\n",
              "      <td>{'طعم': '-2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>خیلی تند هست من که زیاد نمیتونم تو دهن ام نگه ...</td>\n",
              "      <td>-2</td>\n",
              "      <td>آدامس و خوشبو کننده‌ی دهان</td>\n",
              "      <td>{'طعم': '-2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>تکه های ماهی درشت هستند و مثل خیلی از تن ها خر...</td>\n",
              "      <td>1</td>\n",
              "      <td>تن ماهی</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>برای مدرسه بچه ها مناسب است و چون ویتامینه است...</td>\n",
              "      <td>1</td>\n",
              "      <td>شیر</td>\n",
              "      <td>{'ارزش غذایی': '1'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>بطری های عالیس طوری طراحی شدند که نور به هیچ ع...</td>\n",
              "      <td>2</td>\n",
              "      <td>شیر</td>\n",
              "      <td>{'بسته بندی': '2'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e58b8ee9-dd67-4ff0-aa87-ca6cb9f63298')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e58b8ee9-dd67-4ff0-aa87-ca6cb9f63298 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e58b8ee9-dd67-4ff0-aa87-ca6cb9f63298');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"words_count\"] = [len(x.split()) for x in data[\"review\"]]"
      ],
      "metadata": {
        "id": "0BA9v3Tnp5CT"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Essential plots"
      ],
      "metadata": {
        "id": "xsqiJ316mpXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class distributions:\n",
        "\n",
        "  def minmax(data, col_end = 'words_count', col_beg = 'review'):\n",
        "    data[col_end] = data[col_beg].apply(lambda t: len(t.split()))\n",
        "\n",
        "    summary = data[col_end].min(), data[col_end].max(), data[col_end].mean(), np.std(data[col_end])\n",
        "    print(f\" max: {summary[1]} \\n min :{summary[0]}\\n mean : {summary[2]}\\n std : {summary[3]}\")\n",
        "\n",
        "  def word_freq(data, col_end = \"words_count\"):\n",
        "\n",
        "      fig = go.Figure()\n",
        "\n",
        "      fig.add_trace(go.Histogram(\n",
        "          x=data[col_end]\n",
        "      ))\n",
        "\n",
        "      fig.update_layout(\n",
        "          title_text='Distribution of word counts within data',\n",
        "          xaxis_title_text='Word Count',\n",
        "          yaxis_title_text='Frequency',\n",
        "          bargap=0.2,\n",
        "          bargroupgap=0.2)\n",
        "\n",
        "      fig.show()\n",
        "\n",
        "  def data_gl_than(data, less_than=25.0, greater_than=10.0, col='words_count'):\n",
        "      data_length = data[col].values\n",
        "\n",
        "      data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
        "\n",
        "      data_glt_rate = (data_glt / len(data_length)) * 100\n",
        "\n",
        "      print(f'sentences with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')\n",
        "\n",
        "  def full_df_run(data, col_begin = 'sentences', minmax = True, freq = True, gl = True):\n",
        "    if minmax :\n",
        "      distributions.minmax(data)\n",
        "    if freq:\n",
        "      distributions.word_freq(data)\n",
        "    if gl:\n",
        "      distributions.data_gl_than(data)\n",
        "\n",
        "  def word_and_freq(data, col = \"tokenized_sents\"):\n",
        "    tokenized_sent = data[col].values\n",
        "    total_len = 0\n",
        "    for i in range(len(tokenized_sent)):\n",
        "      total_len += len(tokenized_sent[i])\n",
        "\n",
        "    mp_freqdist = FreqDist(itertools.chain(*tokenized_sent))\n",
        "    top20words=mp_freqdist.most_common(20)\n",
        "    print ('%-16s' % 'word', '%-16s' % 'Frequency','%-16s' %  '% of the total')\n",
        "    for topword in top20words:\n",
        "        percent=(topword[1]/total_len)*100\n",
        "        print ('%-16s' % topword[0], '%-16s' % topword[1],'%-16s' %  percent)\n",
        "\n",
        "  def author_count(data, col_auth):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    groupby_rate = data.groupby(col_auth)[col_auth].count()\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=list(sorted(groupby_rate.index)),\n",
        "        y=groupby_rate.tolist(),\n",
        "        text=groupby_rate.tolist(),\n",
        "        textposition='auto'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text='Distribution of authors within sentences',\n",
        "        xaxis_title_text='author',\n",
        "        yaxis_title_text='Frequency',\n",
        "        bargap=0.2,\n",
        "        bargroupgap=0.2)\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "EX0bebwcmn3X"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distributions.full_df_run(data)"
      ],
      "metadata": {
        "id": "c67yQlYmoALE",
        "outputId": "fdf0a5ac-81fd-4db3-87e6-a194dbce6910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " max: 50 \n",
            " min :8\n",
            " mean : 18.62336984872196\n",
            " std : 8.860481005381581\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"4c815707-722a-4b65-b646-aa338bf66a03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4c815707-722a-4b65-b646-aa338bf66a03\")) {                    Plotly.newPlot(                        \"4c815707-722a-4b65-b646-aa338bf66a03\",                        [{\"x\":[21,12,13,30,15,15,18,11,11,14,21,14,13,10,18,19,27,14,44,16,10,21,14,10,10,14,13,37,11,15,27,21,30,13,22,28,36,25,17,23,50,11,13,17,11,30,14,22,14,17,16,10,20,11,32,17,13,19,16,36,12,16,11,19,14,22,28,26,16,11,13,12,24,11,22,10,13,12,35,11,18,11,20,12,15,11,17,33,17,13,12,11,29,11,14,26,14,17,18,22,17,14,28,11,44,10,48,11,14,21,11,37,20,19,13,10,29,28,11,10,11,16,34,11,16,12,27,22,41,25,12,12,44,14,11,11,29,15,14,37,11,13,10,24,12,30,24,28,15,11,24,38,13,27,10,10,25,21,26,11,12,24,15,16,11,25,12,10,18,11,14,11,15,23,20,34,10,26,15,30,28,30,13,10,16,21,12,11,12,11,13,10,16,15,30,38,18,13,17,41,11,50,11,11,13,15,15,26,12,16,11,17,47,31,19,24,13,25,10,13,15,13,16,14,20,17,11,21,10,10,47,37,14,10,18,12,12,13,17,13,16,12,11,21,29,10,41,10,14,17,16,12,14,31,19,10,13,12,18,10,16,11,18,10,16,14,18,28,13,29,47,18,11,21,26,15,12,14,11,12,16,19,12,22,14,12,17,37,17,12,22,27,19,15,11,10,13,15,45,17,10,16,23,20,20,11,18,12,12,11,18,15,32,11,11,35,35,25,12,14,11,22,34,10,11,37,9,15,13,24,20,11,12,14,13,15,20,17,46,12,18,16,40,13,20,14,23,23,50,25,17,16,40,40,28,19,26,27,13,15,20,19,33,29,11,24,10,14,22,10,28,12,10,15,42,15,10,28,18,11,11,23,13,27,11,14,10,20,37,13,43,12,10,23,18,14,19,18,17,13,26,34,13,12,12,15,20,24,15,15,11,39,16,14,10,9,15,18,23,14,28,13,21,12,23,10,15,12,11,30,17,24,15,15,17,14,11,47,20,10,10,17,10,10,27,10,10,29,19,12,17,10,11,11,15,18,32,14,11,13,30,11,10,13,20,18,22,11,31,27,22,11,18,18,12,31,18,14,12,15,10,21,21,11,11,15,11,44,10,15,23,20,12,22,13,29,16,12,23,11,12,12,12,15,28,16,16,12,12,14,18,11,17,12,20,18,10,36,25,12,12,39,16,12,11,20,22,16,11,12,25,13,14,14,39,35,25,13,45,25,10,12,20,23,11,47,16,14,11,11,10,10,29,15,22,10,23,12,10,11,15,10,30,11,30,25,13,13,23,26,18,16,10,12,18,13,11,14,28,14,26,10,11,15,29,44,26,19,13,22,13,14,11,12,14,12,27,19,22,12,13,11,17,26,20,16,14,17,22,17,10,17,16,12,11,10,16,28,28,12,11,27,24,12,33,13,11,11,14,23,11,33,12,10,16,33,10,13,14,21,22,14,10,18,17,46,11,34,19,35,38,18,20,15,18,13,17,12,10,16,13,46,10,10,12,25,20,13,15,15,46,29,11,19,19,26,44,14,10,19,14,22,12,12,29,11,34,11,17,12,12,10,15,36,19,11,15,10,16,10,32,21,34,43,11,14,18,16,13,13,22,17,31,16,18,10,24,17,12,16,14,27,10,10,9,12,20,11,16,13,27,18,11,18,17,12,35,15,42,25,10,12,10,11,47,32,11,46,13,23,11,33,30,33,45,29,14,15,12,24,10,16,18,23,18,19,15,13,17,50,24,11,15,15,18,41,16,16,22,21,26,15,15,11,10,11,15,33,17,29,27,13,12,29,11,13,11,25,13,15,33,24,46,14,20,26,16,13,11,16,19,21,10,41,40,20,23,14,10,10,10,17,16,19,25,15,44,14,11,19,18,12,14,30,30,31,12,10,19,18,18,20,19,16,11,12,22,14,13,10,31,25,32,34,19,16,19,16,10,11,41,16,21,13,39,10,17,10,13,22,18,10,15,9,18,11,26,16,13,11,10,15,16,10,10,16,10,10,11,10,11,16,17,19,11,10,12,13,16,39,18,15,37,15,15,24,20,10,46,11,35,18,12,12,14,19,13,15,12,36,21,36,10,10,15,10,15,28,17,12,28,35,10,26,12,10,13,10,13,13,36,27,10,19,39,13,25,8,11,29,17,23,19,11,11,15,15,22,10,33,11,12,17,33,24,12,27,12,39,11,23,12,39,17,13,19,10,27,10,10,13,24,13,34,12,15,10,10,13,17,16,26,22,16,17,20,10,13,12,24,16,22,27,11,13,10,35,20,20,12,16,15,40,14,38,19,21,10,21,23,35,29,17,18,26,17,19,10,15,19,32,34,20,12,15,50,14,32,14,17,13,11,32,12,13,27,16,30,13,17,25,22,13,13,19,20,12,11,16,23,37,10,10,15,10,22,25,27,20,50,10,15,26,14,12,14,32,10,11,20,17,20,24,30,21,12,17,10,14,16,11,11,10,14,39,14,10,11,33,31,24,32,39,31,11,13,35,12,16,11,19,35,27,13,28,11,14,10,15,13,18,14,11,41,12,43,12,12,20,14,27,28,12,13,11,11,27,17,16,17,39,26,12,21,30,28,13,24,31,11,28,38,11,11,28,18,11,19,14,12,11,14,12,11,26,31,49,29,12,12,16,29,24,27,12,14,19,21,25,26,20,10,23,27,40,10,24,10,15,10,23,13,17,11,19,19,20,19,15,12,12,11,46,31,13,11,13,38,11,20,13,11,21,36,26,32,15,22,13,12,15,18,25,11,10,38,27,20,38,17,10,20,12,14,14,28,28,18,22,21,13,13,15,13,48,14,16,10,11,21,10,10,23,10,33,10,18,14,10,29,17,12,13,37,39,14,18,20,30,11,23,13,10,11,26,16,19,15,13,33,15,13,25,36,14,34,22,23,14,13,17,26,10,11,15,17,22,32,13,13,16,10,14,12,35,12,10,11,14,16,22,11,19,17,26,11,37,13,12,12,10,11,12,22,27,11,24,16,10,40,10,14,21,12,47,11,10,22,24,13,29,31,12,28,10,12,10,23,13,22,13,12,14,12,11,21,14,10,12,10,11,26,21,13,11,16,10,34,17,14,13,17,12,16,14,11,21,12,14,50,18,10,35,13,10,18,42,17,10,23,19,24,19,13,20,12,25,13,34,12,15,14,16,24,20,17,16,10,18,17,14,17,11,16,12,17,17,13,13,22,10,30,12,39,10,23,10,29,11,10,22,10,10,28,14,18,25,14,18,14,18,14,11,46,13,16,41,11,34,12,25,28,16,28,13,35,11,21,11,11,30,24,10,25,20,50,18,12,11,12,15,26,10,25,31,23,11,17,10,19,28,11,39,20,10,12,13,29,17,10,16,15,27,13,10,10,25,19,32,15,13,13,16,13,28,34,33,10,8,20,32,19,28,13,40,23,22,12,14,15,11,20,18,11,16,14,27,13,11,16,33,32,23,19,11,14,17,10,15,15,18,16,11,34,46,14,12,28,17,12,10,10,10,15,16,10,22,11,16,10,14,14,14,10,32,11,32,11,16,21,31,13,14,30,11,18,40,18,17,17,10,13,14,16,12,17,11,17,26,31,49,23,15,17,30,13,19,22,14,20,26,19,19,15,12,15,23,17,24,10,44,11,14,14,15,12,12,25,25,11,35,21,11,13,13,13,43,10,11,25,20,12,18,16,12,16,17,14,10,18,12,22,15,21,10,27,10,20,14,24,11,25,19,27,12,14,17,13,18,37,24,15,15,34,11,21,30,19,10,37,29,22,21,12,19,10,20,10,25,11,15,11,36,12,15,20,12,16,50,19,23,43,16,11,22,10,14,46,15,25,19,13,26,15,10,15,14,10,20,10,13,14,11,17,21,18,42,12,11,11,23,22,18,10,14,13,18,12,12,18,36,14,18,17,24,11,13,13,12,12,13,18,12,37,21,45,21,10,12,25,33,11,11,17,18,24,30,16,10,13,13,17,17,14,11,12,30,15,21,14,19,19,11,13,22,17,16,11,13,31,26,23,23,13,11,29,11,16,12,14,26,20,14,15,35,16,22,13,41,37,39,15,16,13,14,11,17,20,33,13,12,21,24,14,33,12,10,14,23,27,10,10,21,15,23,12,11,31,27,14,38,17,11,19,21,11,16,10,10,50,18,11,21,10,17,28,12,14,14,15,16,12,45,13,15,22,20,45,10,20,11,21,16,10,17,38,20,14,10,21,12,12,29,16,15,21,17,10,15,20,29,10,16,17,10,16,46,13,11,11,20,14,13,33,19,25,10,19,10,23,12,10,15,12,41,17,14,11,11,16,16,39,15,14,12,22,12],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Distribution of word counts within data\"},\"xaxis\":{\"title\":{\"text\":\"Word Count\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4c815707-722a-4b65-b646-aa338bf66a03');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences with word length of greater than 10.0 and less than 25.0 includes 70.06% of the whole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Document classification"
      ],
      "metadata": {
        "id": "Eiegma7PoVMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tf-Idf"
      ],
      "metadata": {
        "id": "90Ic9CjoueLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "einz08mkudyk"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [text for text in data[\"review\"]]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "vhSrD61eu0MO",
        "outputId": "a4b05d8e-41bd-4bc5-b668-927af022a088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['10', '1000', '12', ..., '۹۰۰', '۹۵', '۹۸۰۰'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM linear kernel"
      ],
      "metadata": {
        "id": "3suEqk9wojvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##related to scaling and splitting\n",
        "\n",
        "y = df['y-axis-mean']\n",
        "df.drop(columns={'y-axis-mean'},inplace=True)\n",
        "x=df\n",
        "\n",
        "##personally have a feeling that minmax scaler would by far be the better one\n",
        "\n",
        "x=MinMaxScaler().fit_transform(x)\n",
        "X_train , x_test , Y_train , y_test = tts(x,y,test_size = 0.1 , random_state = 42)\n",
        "x_train , x_val , y_train , y_val = tts(X_train,Y_train,test_size=0.1,random_state=42)"
      ],
      "metadata": {
        "id": "a7KYNar-wVqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = dict(kernel=['linear'],C = [5e-3,1e-2,5e-2,1e-1,5e-1,1])"
      ],
      "metadata": {
        "id": "Dd-XiA0Zweay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Preprocess data<br/>implement the cross validation function"
      ],
      "metadata": {
        "id": "JTNoSqp0ozKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train and evaluation section"
      ],
      "metadata": {
        "id": "3-emcgyypLQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_model = svm.SVC(max_iter=1000,probability=True,verbose=False)\n",
        "model_acc = GridSearchCV(estimator=random_model.copy(),param_distributions=parameters,n_iter=6,n_jobs=-1,cv=10,scoring='accuracy',refit=True)\n",
        "model_f1 = GridSearchCV(estimator=random_model.copy(),param_distributions=parameters,n_iter=6,n_jobs=-1,cv=10,scoring='f1',refit=True)\n",
        "model_rac = GridSearchCV(estimator=random_model.copy(),param_distributions=parameters,n_iter=6,n_jobs=-1,cv=10,scoring='roc_auc',refit=True)"
      ],
      "metadata": {
        "id": "KYU2QKCfw7jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'score of model with score set to accuracy :{model_acc.best_score_}\\nparameters of model with score set to accuracy:{model_acc.best_params_}\\n-------')\n",
        "print(f'score of model with score set to f1 :{model_f1.best_score_}\\nparameters of model with score set to f1:{model_f1.best_params_}\\n-----------')\n",
        "print(f'score of model with score set to roc-auc :{model_rac.best_score_}\\nparameters of model with score set to roc-auc:{model_rac.best_params_}\\n----------')"
      ],
      "metadata": {
        "id": "X-LybhEkxr4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_curve(model,title,score):\n",
        "  y_score = model.predict_proba(x)[:, 1]\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y, y_score)\n",
        "\n",
        "  fig = px.area(\n",
        "      x=fpr, y=tpr,\n",
        "      title=f'{title}\\'s ROC Curve (AUC={auc(fpr, tpr):.4f})  -- score:{score}',\n",
        "      labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "      width=700, height=500\n",
        "  )\n",
        "  fig.add_shape(\n",
        "      type='line', line=dict(dash='dash'),\n",
        "      x0=0, x1=1, y0=0, y1=1\n",
        "  )\n",
        "\n",
        "  fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "  fig.update_xaxes(constrain='domain')\n",
        "  fig.show()\n",
        "\n",
        "roc_curve(model_acc,\"Model_acc\",\"accuracy\")\n",
        "roc_curve(model_f1,\"Model_f1\",\"f1\")\n",
        "roc_curve(model_rac,\"Model_rac\",\"roc_auc\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Soa3p75tx0an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prec_recall(model,title,score):\n",
        "\n",
        "  y_score = model.predict_proba(x)[:, 1]\n",
        "  precision, recall, thresholds = precision_recall_curve(y, y_score)\n",
        "\n",
        "  fig = px.area(\n",
        "      x=recall, y=precision,\n",
        "      title=f'{title}\\'s Precision-Recall Curve (AUC={auc(precision, recall):.4f}) -- score : {score}',\n",
        "      labels=dict(x='Recall', y='Precision'),\n",
        "      width=700, height=500\n",
        "  )\n",
        "  fig.add_shape(\n",
        "      type='line', line=dict(dash='dash'),\n",
        "      x0=0, x1=1, y0=1, y1=0\n",
        "  )\n",
        "  fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "  fig.update_xaxes(constrain='domain')\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "prec_recall(model_acc,\"Model_acc\",\"accuracy\")\n",
        "prec_recall(model_f1,\"Model_f1\",\"f1\")\n",
        "prec_recall(model_rac,\"Model_rac\",\"roc_auc\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tVeV9eI2x81A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_curve(model,x,y,fold,title):\n",
        "  train_sizes, train_scores, test_scores = learning_curve(estimator=model, X=x, y=y,cv=fold,)\n",
        "  train_mean = np.mean(train_scores, axis=1)\n",
        "  train_std = np.std(train_scores, axis=1)\n",
        "  test_mean = np.mean(test_scores, axis=1)\n",
        "  test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "  plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
        "  plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
        "  plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
        "  plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
        "  plt.title(f'Learning Curve for {title}')\n",
        "  plt.xlabel('Training Data Size')\n",
        "  plt.ylabel('Model accuracy')\n",
        "  plt.grid()\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "learning_curve(model_acc,X_train,Y_train,10,\"Model_acc\")\n",
        "learning_curve(model_f1,X_train,Y_train,10,\"Model_f1\")\n",
        "learning_curve(model_rac,X_train,Y_train,10,\"Model_rac\")"
      ],
      "metadata": {
        "id": "pYQeziB0yK7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test"
      ],
      "metadata": {
        "id": "Cz5jz2SFpQuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transformer-based model"
      ],
      "metadata": {
        "id": "Zcnv5eAvomaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beF-TcxQnlh2"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = tts(new_data, test_size=0.2, random_state=1, stratify=new_data['author'])\n",
        "train, valid = tts(train, test_size=0.2, random_state=1, stratify=train['author'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = train['normalized_sents'].values.tolist(), train['author'].values.tolist()\n",
        "x_valid, y_valid = valid['normalized_sents'].values.tolist(), valid['author'].values.tolist()\n",
        "x_test, y_test = test['normalized_sents'].values.tolist(), test['author'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgpgqS690oCs",
        "outputId": "211e61a3-12da-4b2a-ef70-6680555e1596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8662, 3)\n",
            "(2166, 3)\n",
            "(2708, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "##### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpUoggdpU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4bf8c1-6958-4030-a80e-5024bc37ff56"
      },
      "source": [
        "##sit the model on the gpu\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "CUDA is not available.  Training on CPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "source": [
        "# general config\n",
        "##to be changed....\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 3\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'bert-base-uncased'\n",
        "OUTPUT_PATH = '/auth_classification_bert/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK02AC0pYIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e253d9-5ef7-430b-fee0-ecbe2f850bfb"
      },
      "source": [
        "# create a key finder based on label 2 id and id to label\n",
        "##tokenizing the labels in a handy way\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(name_list)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {'heg': 0, 'kan': 1, 'nei': 2}\n",
            "id2label: {0: 'heg', 1: 'kan', 2: 'nei'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGJRNBXFYOcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720,
          "referenced_widgets": [
            "377d8e293359446b99f3b7ea5bdc737d",
            "495c255035884aa5a8da622436236e58",
            "e0d82cfe3881405bad467225c133560d",
            "88a694d864b1433db7a645dd34275e45",
            "27d4ff12baf044929834f7130e9e36ba",
            "4ff8d0650648483faa202b3967900b28",
            "9a42d8d128e343febd16f8b8722ab8e9",
            "98be237063a2478e940195e444875227",
            "57617fb77add48a5a4c15abcd378337f",
            "73f37267f9c74138923c6817bc1395f7",
            "51928147e32b4574bcda4f0973e72d83",
            "a3551d28e040490db5ea870b1d948e5c",
            "3edcdab82973416496799c19df581c73",
            "54b1687fb0274dd8943def2266e34862",
            "a6f50e005b7f4d288b405691e7ff2fb3",
            "73f8cb3cd4f245ffb0e3e3db307c639b",
            "4d85d4abae9a48098d7daf8bda8f0f3f",
            "1e49e5eb5422429389424ef25115b33e",
            "31769353f33646c29bfddd3f2000c653",
            "3225458632e54955b3f9fd0159881557",
            "8b126a7ddfe84766a830af00a9598a34",
            "51909caf394d426eaa15244fb2f8e621",
            "4f727d83a9ef410cb74366ee098da5fe",
            "551f3b75e95343c2ab426f5b59221a85",
            "538036bf888d42c4a9e4097a17c06d0a",
            "c70af5437664409ab23b005ccb01dbd5",
            "415dbca238564a9baa4bd33c28334a5e",
            "4f6d1c7f49c740c49844c100dcecf637",
            "e9085f40d1e44b7f9099be07086aa6f7",
            "2749c634c75c45ea9cd33a9c5ac717e5",
            "d79501f98e3b426fb802ca06eac92713",
            "fffa1fc85e6e4a42a83d5ade2a7ca647",
            "c5afe3eda8d34e259dcb65d7d1d9a5d9"
          ]
        },
        "outputId": "dcf8ca5c-0bcc-491f-d237-c2c3e216d1f3"
      },
      "source": [
        "# setup the tokenizer and configuration\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "config = BertConfig.from_pretrained(\n",
        "    MODEL_NAME_OR_PATH, **{\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label,\n",
        "    })\n",
        "\n",
        "print(config.to_json_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377d8e293359446b99f3b7ea5bdc737d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3551d28e040490db5ea870b1d948e5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f727d83a9ef410cb74366ee098da5fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"heg\",\n",
            "    \"1\": \"kan\",\n",
            "    \"2\": \"nei\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"heg\": 0,\n",
            "    \"kan\": 1,\n",
            "    \"nei\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.27.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "##### Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BIajCqGgYEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a2b0dd-dc98-4064-f7ba-b7e3e7211fd5"
      },
      "source": [
        "idx = np.random.randint(0, len(train))\n",
        "sample_sent = train.iloc[idx]['normalized_sents']\n",
        "sample_auth = train.iloc[idx]['author']\n",
        "\n",
        "print(f'Sample: \\n{\" \".join(sample_sent)}\\n{sample_auth}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: \n",
            "proof one perhaps say immediately con scious representation external things consequently still remains undecided whether something outside corresponding\n",
            "kan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygnLJu8uhjPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a0803f-13f0-4039-d203-3f9ab224c48d"
      },
      "source": [
        "tokens = sample_sent\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'  sentence: {\" \".join(sample_sent)}')\n",
        "print(f'  Coded_tokens: {tokens}')\n",
        "print(f'   Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentence: proof one perhaps say immediately con scious representation external things consequently still remains undecided whether something outside corresponding\n",
            "  Coded_tokens: ['proof', 'one', 'perhaps', 'say', 'immediately', 'con', 'scious', 'representation', 'external', 'things', 'consequently', 'still', 'remains', 'undecided', 'whether', 'something', 'outside', 'corresponding']\n",
            "   Tokens: proof one perhaps say immediately con scious representation external things consequently still remains undecided whether something outside corresponding\n",
            "Token IDs: [6947, 2028, 3383, 2360, 3202, 9530, 100, 6630, 6327, 2477, 8821, 2145, 3464, 100, 3251, 2242, 2648, 7978]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgsgZ2b5h2I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a797527-dd2b-4556-b98a-c5bd1a3f7638"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample_sent,\n",
        "    max_length=32,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "print(f'Keys: {encoding.keys()}\\n')\n",
        "for k in encoding.keys():\n",
        "    print(f'{k}:\\n{encoding[k]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "\n",
            "input_ids:\n",
            "tensor([[ 101, 6947, 2028, 3383, 2360, 3202, 9530,  100, 6630, 6327, 2477, 8821,\n",
            "         2145, 3464,  100, 3251, 2242, 2648, 7978,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "token_type_ids:\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask:\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "##### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "source": [
        "class PhilDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, sent, targets=None, label_list=None, max_len=128):\n",
        "        self.sent = sent\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "\n",
        "        self.label_map = {label: i for i, label in enumerate(label_list)} if isinstance(label_list, list) else {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sent)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sentence = str(self.sent[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.targets[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        inputs = {\n",
        "            'sentence': sentence,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, label_list):\n",
        "    dataset = PhilDataset(\n",
        "        sent=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len,\n",
        "        label_list=label_list)\n",
        "\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "source": [
        "label_list = name_list\n",
        "train_data_loader = create_data_loader(train['normalized_sents'].to_numpy(), train['labels'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, label_list)\n",
        "valid_data_loader = create_data_loader(valid['normalized_sents'].to_numpy(), valid['labels'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, label_list)\n",
        "test_data_loader = create_data_loader(test['normalized_sents'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qSxzPU2krDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec40e38-947e-4ecc-b161-6ebc12534227"
      },
      "source": [
        "sample_data = next(iter(train_data_loader))\n",
        "\n",
        "print(sample_data.keys())\n",
        "\n",
        "print(sample_data['sentence'])\n",
        "print(sample_data['input_ids'].shape)\n",
        "print(sample_data['input_ids'][0, :])\n",
        "print(sample_data['attention_mask'].shape)\n",
        "print(sample_data['attention_mask'][0, :])\n",
        "print(sample_data['token_type_ids'].shape)\n",
        "print(sample_data['token_type_ids'][0, :])\n",
        "print(sample_data['targets'].shape)\n",
        "print(sample_data['targets'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['sentence', 'input_ids', 'attention_mask', 'token_type_ids', 'targets'])\n",
            "[\"['employ', 'innovations', 'quaint', 'old', 'terms', 'language', 'favour', 'rare', 'strange', 'concerned', 'aug\\\\xad', 'ment', 'vocabulary', 'rather', 'restrict', 'always', 'sign', 'immature', 'corrupted', 'taste']\", \"['notion', 'consciousness', 'forms', 'absolute', 'interfusion', 'individuality', 'let', 'see', 'whether', 'notion', 'confirmed', 'experience', 'whether', 'reality', 'corresponds']\", \"['one', 'indi\\\\xad', 'vidual', 'needs', 'health', 'another', 'cause', 'sickness', 'many', 'ways', 'means', 'freedom', 'spirit', 'may', 'highly', 'developed', 'natures', 'count', 'ways', 'means', 'unfreedom']\", \"['deceiving', 'priesthodd', 'dppressive', 'despot', 'therefore', 'ndt', 'directly', 'dbject', 'activity', 'object', 'insight', 'devoid']\", \"['individual', 'rules', 'life', 'excite', 'hostility', 'adopts', 'people', 'feel', 'humiliated', 'exceptional', 'treatment', 'accords', 'though', 'treated', 'merely', 'commonplace', 'creatures']\", \"['words', 'shape', 'yet', 'form', 'notion']\", \"['thought', 'highly', 'convictions', 'brought', 'sacrifices', 'every', 'kind', 'spared', 'honour', 'body', 'life', 'service', 'de\\\\xad', 'voted', 'half', 'energy', 'investigating', 'right', 'adhered', 'conviction', 'path', 'arrived', 'peaceable', 'picture', 'history', 'mankind', 'would', 'present']\", \"['never', 'get', 'crowd', 'cry', 'hosanna', 'ride', 'town', 'ass']\", \"['good', 'actions', 'sublimated', 'evil', 'ones', 'evil', 'actions', 'coarsened', 'brutalized', 'good', 'ones']\", \"['judging', 'consciousness', 'meant', 'quite', 'contrary']\", \"['second', 'principle', 'realities', 'mere', 'affirmations', 'never', 'log', 'ically', 'oppose', 'entirely', 'true', 'proposition', 'relaa', 'tions', 'concepts', 'signifies', 'nothing', 'either', 'regard', 'nature', 'overall', 'regard', 'anything', 'concept']\", \"['aware', 'objectively', 'real', 'world']\", \"['deal', 'unconditioned', 'causality', 'unconditioned', 'existence', 'substance']\", \"['one', 'absolute', 'pure', 'thinking', 'imme\\\\xad', 'diately', 'pure', 'consciousness', 'outside', 'finite', 'consciousness', 'negative', 'beyond']\", \"['use', 'notes', 'references', 'marginal', 'pag\\\\xad', 'ination', 'show', 'changes', 'made', 'first', 'second', 'editions']\", \"['although', 'general', 'logic', 'give', 'precepts', 'power', 'judgment', 'things', 'quite', 'different', 'transcendental', 'logic', 'even', 'seems', 'latter', 'proper', 'business', 'correct', 'secure', 'power', 'judgment', 'use', 'pure', 'understanding', 'determinate', 'rules']\"]\n",
            "torch.Size([16, 128])\n",
            "tensor([  101,  1031,  1005, 12666,  1005,  1010,  1005, 15463,  1005,  1010,\n",
            "         1005, 24209, 22325,  1005,  1010,  1005,  2214,  1005,  1010,  1005,\n",
            "         3408,  1005,  1010,  1005,  2653,  1005,  1010,  1005,  7927,  1005,\n",
            "         1010,  1005,  4678,  1005,  1010,  1005,  4326,  1005,  1010,  1005,\n",
            "         4986,  1005,  1010,  1005, 15476,  1032,  1060,  4215,  1005,  1010,\n",
            "         1005,  2273,  2102,  1005,  1010,  1005, 16188,  1005,  1010,  1005,\n",
            "         2738,  1005,  1010,  1005, 21573,  1005,  1010,  1005,  2467,  1005,\n",
            "         1010,  1005,  3696,  1005,  1010,  1005, 26838,  1005,  1010,  1005,\n",
            "        27279,  1005,  1010,  1005,  5510,  1005,  1033,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "torch.Size([16, 128])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([16, 128])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "torch.Size([16])\n",
            "tensor([2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDUNgRODuOTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2eb05f0-abbe-4db3-ce5e-d53907f4059f"
      },
      "source": [
        "sample_test = next(iter(test_data_loader))\n",
        "print(sample_test.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['sentence', 'input_ids', 'attention_mask', 'token_type_ids'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "source": [
        "class ClassifierModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(ClassifierModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 10)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)['pooler_output']\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrObbZAdNTNl"
      },
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vzQGZGUmw3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56207d4-0d60-4d2e-852a-7b300f703f3e"
      },
      "source": [
        "pt_model = ClassifierModel(config=config)\n",
        "pt_model = pt_model.to(device)\n",
        "\n",
        "print('pt_model', type(pt_model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.ClassifierModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name,param in pt_model.named_parameters():\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "Lr_-sMgyTNfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZQDfLlp0Sf"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "import copy\n",
        "import collections\n",
        "import torch"
      ],
      "metadata": {
        "id": "o3peRYrH4ykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "source": [
        "def simple_accuracy(y_true, y_pred):\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    acc = simple_accuracy(y_true, y_pred)\n",
        "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation... \"):\n",
        "\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            targets = dl['targets']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "\n",
        "            # convert output probabilities to predicted class\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # calculate the batch loss\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            # accumulate all the losses\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "\n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model,\n",
        "             data_loader,\n",
        "             loss_fn,\n",
        "             optimizer,\n",
        "             scheduler,\n",
        "             step=0,\n",
        "             print_every_step=100,\n",
        "             eval=False,\n",
        "             eval_cb=None,\n",
        "             eval_loss_min=np.Inf,\n",
        "             eval_data_loader=None,\n",
        "             clip=0.0):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    for dl in tqdm(data_loader, total=len(data_loader), desc=\"Training... \"):\n",
        "        step += 1\n",
        "\n",
        "        input_ids = dl['input_ids']\n",
        "        attention_mask = dl['attention_mask']\n",
        "        token_type_ids = dl['token_type_ids']\n",
        "        targets = dl['targets']\n",
        "\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "\n",
        "        # convert output probabilities to predicted class\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # accumulate all the losses\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        if eval:\n",
        "            train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "            train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "            if step % print_every_step == 0:\n",
        "                eval_y, eval_loss = eval_op(model, eval_data_loader, loss_fn)\n",
        "                eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "                if hasattr(eval_cb, '__call__'):\n",
        "                    eval_loss_min = eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min)\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_loss_min\n",
        "\n",
        "def eval_callback(epoch, epochs, output_path):\n",
        "    def eval_cb(model, step, train_score, train_loss, eval_score, eval_loss, eval_loss_min):\n",
        "        statement = ''\n",
        "        statement += 'Epoch: {}/{}...'.format(epoch, epochs)\n",
        "        statement += 'Step: {}...'.format(step)\n",
        "\n",
        "        statement += 'Train Loss: {:.6f}...'.format(train_loss)\n",
        "        statement += 'Train Acc: {:.3f}...'.format(train_score['acc'])\n",
        "\n",
        "        statement += 'Valid Loss: {:.6f}...'.format(eval_loss)\n",
        "        statement += 'Valid Acc: {:.3f}...'.format(eval_score['acc'])\n",
        "\n",
        "        print(statement)\n",
        "\n",
        "        if eval_loss <= eval_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                eval_loss_min,\n",
        "                eval_loss))\n",
        "\n",
        "            torch.save(model.state_dict(), output_path)\n",
        "            eval_loss_min = eval_loss\n",
        "\n",
        "        return eval_loss_min\n",
        "\n",
        "\n",
        "    return eval_cb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWrdialDAtN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7e1f4837ac5542b69ba1f1fe3ecc1e9e",
            "5f53d3910ccb4ed8852f48567728122d",
            "f4b79e679e3b4116a7dc0cf85b5bbd79",
            "342df4eaabe543338af304faa3d8f945",
            "1d4b516f7e2843b29c1f294d19c497d1",
            "c973e17cc29f470aad4f88d9a1a03e0e",
            "ab97eedadcd54386a3a8ffbb8a4616b5",
            "aa938851d687499ba3fe97abedb127eb",
            "b72466527eac410896e3a2b70084898c",
            "a35c73fb2bbd45de9be4e42e36f07240",
            "bfb4ea4aeae04b7193c2949162aa01d2",
            "6713ec0510974eb2bba7bb755481b69d",
            "6736652ca7f24dd5a7b954ef76314d72",
            "a2ac6446c55d497d90b08a802ba8d3ef",
            "4b177dbcb3e741858fba042dd22c3f8a",
            "4938745fcc7644d3864ff21d32680d85",
            "f2491f9fd8474439ae14822376e1a677",
            "ddff20efa3dd4081be9f283c68cd4c1f",
            "a536b427160146319753fb221683caa7",
            "435355c2d03247df96f071b1cff5596a",
            "b8c7771a6cc848759a01d959a54bb028",
            "8ca95e8364d34d339c5c872fd988a92f"
          ]
        },
        "outputId": "723b03fd-83be-49ba-cc57-c3cb10482928"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(pt_model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "step = 0\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"Epochs... \"):\n",
        "    train_y, train_loss, step, eval_loss_min = train_op(\n",
        "        model=pt_model,\n",
        "        data_loader=train_data_loader,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        step=step,\n",
        "        print_every_step=EEVERY_EPOCH,\n",
        "        eval=True,\n",
        "        eval_cb=eval_callback(epoch, EPOCHS, OUTPUT_PATH),\n",
        "        eval_loss_min=eval_loss_min,\n",
        "        eval_data_loader=valid_data_loader,\n",
        "        clip=CLIP)\n",
        "\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "\n",
        "    eval_y, eval_loss = eval_op(\n",
        "        model=pt_model,\n",
        "        data_loader=valid_data_loader,\n",
        "        loss_fn=loss_fn)\n",
        "\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs... :   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e1f4837ac5542b69ba1f1fe3ecc1e9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training... :   0%|          | 0/542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6713ec0510974eb2bba7bb755481b69d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "##### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlpDbg0wDqKP"
      },
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "\n",
        "            # compute predicted outputs by passing inputs to the model\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "\n",
        "            # convert output probabilities to predicted class\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRpWTfwdoWoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ed41d53c9c2d4293847d6cba92678bc6",
            "b4c0de9cad2c4c51b99e7312af80f309",
            "01e9320dfc554ce4962e307bd46f719d",
            "bc5e097111d942e3ba5e8d5b3e1fecdf",
            "03c2c140d77d4e5b8682d993d5b0bf27",
            "36f5270be00d4316a4761c01b7df2c8e",
            "df6d404c345345548f615b8143ea3892",
            "66d4b5c390204095a6f3177a1d198041",
            "dab64da309014ca1a57bade6d1c55e5e",
            "293931024d0c4dd7a48720fafe0ce7c2",
            "8158df6c3dc3421592b6b248040a3fa5"
          ]
        },
        "outputId": "9fb11768-a77c-4159-c48d-46325a57d33d"
      },
      "source": [
        "test_sents = test['normalized_sents'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_sents, tokenizer, max_len=128)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/590 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed41d53c9c2d4293847d6cba92678bc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18860,) (18860, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNlmNh7jazk7",
        "outputId": "12e6e1b1-1d6b-4075-954d-5b5faa01dea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 5, 5, ..., 3, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_label = [id2label[t] for t in preds]\n",
        "preds_label[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD-if3dzbK69",
        "outputId": "7d779734-a6e7-4093-b57a-b716aa31cafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parvin', 'hafez', 'hafez', 'asad', 'asadi']"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####F1 Score and report"
      ],
      "metadata": {
        "id": "Vzor4JVfYv38"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRL2bgDDpUG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f223cd-44e4-4e80-bcf0-8cd66fb03fd3"
      },
      "source": [
        "y_test, y_pred = test['author'].values, preds\n",
        "\n",
        "print(f'F1: {f1_score(y_test, y_pred, average=\"weighted\")}')\n",
        "print(\"--------------classification_report---------------\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.18183054145230343\n",
            "--------------classification_report---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      khajoo       0.19      0.06      0.09      1886\n",
            "        asad       0.17      0.23      0.19      1886\n",
            "       bahar       0.18      0.21      0.19      1886\n",
            "        feyz       0.20      0.20      0.20      1886\n",
            "       asadi       0.28      0.41      0.33      1886\n",
            "       hafez       0.18      0.26      0.21      1886\n",
            "        jami       0.15      0.17      0.16      1886\n",
            "       kamal       0.16      0.12      0.14      1886\n",
            "     moulavi       0.22      0.09      0.13      1886\n",
            "      parvin       0.18      0.17      0.17      1886\n",
            "\n",
            "    accuracy                           0.19     18860\n",
            "   macro avg       0.19      0.19      0.18     18860\n",
            "weighted avg       0.19      0.19      0.18     18860\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "d7ZQQDSDd1Iu",
        "outputId": "aa8903c4-4907-43c1-f369-635dd62886c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[108 230 135 240 211 368 175 178 102 139]\n",
            " [ 42 427 178 172 363 210 164 122  41 167]\n",
            " [ 28 186 396 131 281 199 247 122  90 206]\n",
            " [ 61 231 157 370  91 361 230 155  83 147]\n",
            " [ 23 258 233  63 769  90 154 103  29 164]\n",
            " [ 79 231 181 217 104 495 202 149  80 148]\n",
            " [ 52 200 255 146 294 210 317 132  70 210]\n",
            " [ 74 261 182 222 209 282 201 229  86 140]\n",
            " [ 34 281 270 161 189 241 237 149 178 146]\n",
            " [ 53 242 263 138 199 292 202 131  48 318]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Preprocess data(add token, tokenizaiton, padding)"
      ],
      "metadata": {
        "id": "ZU6dgtmppQIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train and evaluation section"
      ],
      "metadata": {
        "id": "KTR8U0QgpgwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test"
      ],
      "metadata": {
        "id": "KWTr0ohHpi_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Token classification"
      ],
      "metadata": {
        "id": "rkpVHmoAofvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GRU and LSTM"
      ],
      "metadata": {
        "id": "byjufE1JoqdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "        num_classes,\n",
        "        batch_size=10,\n",
        "        embedding_dim=100,\n",
        "        hidden_dim=50,\n",
        "        vocab_size=128):\n",
        "\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        initrange = 0.1\n",
        "\n",
        "        self.num_labels = num_classes\n",
        "        n = len(self.num_labels)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.word_embeddings.weight.data.uniform_(-initrange, initrange)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, bidirectional=True)  # !\n",
        "\n",
        "        print(\"# !\")\n",
        "\n",
        "        bi_grus = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, bidirectional=True)\n",
        "        reverse_gru = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True, bidirectional=False)\n",
        "\n",
        "        self.lstm.weight_ih_l0_reverse = bi_grus.weight_ih_l0_reverse\n",
        "        self.lstm.weight_hh_l0_reverse = bi_grus.weight_hh_l0_reverse\n",
        "        self.lstm.bias_ih_l0_reverse = bi_grus.bias_ih_l0_reverse\n",
        "        self.lstm.bias_hh_l0_reverse = bi_grus.bias_hh_l0_reverse\n",
        "\n",
        "        bi_output, bi_hidden = bi_grus()\n",
        "        reverse_output, reverse_hidden = reverse_gru()\n",
        "\n",
        "        print(\"# !\")\n",
        "\n",
        "        # self.classifier = nn.Linear(hidden_dim, self.num_labels[0])\n",
        "        self.classifier = nn.Linear(2 * hidden_dim, self.num_labels[0])  # !\n",
        "\n",
        "\n",
        "    def repackage_hidden(h):\n",
        "        \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "        if isinstance(h, torch.Tensor):\n",
        "            return h.detach()\n",
        "        else:\n",
        "            return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "    def forward(self, sentence, labels=None):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)  # lstm_out - 2 tensors, _ - hidden layer\n",
        "        print(lstm_out[:,-1,:])\n",
        "        tag_space = self.classifier(lstm_out[:,-1,:] + lstm_out[:,-1,:])  # !  # lstm_out[:,-1,:] - 1 tensor\n",
        "        logits = F.log_softmax(tag_space, dim=1)\n",
        "        loss = None\n",
        "        if labels:\n",
        "            loss = F.cross_entropy(logits.view(-1, self.num_labels[0]), labels[0].view(-1))\n",
        "        return loss, logits"
      ],
      "metadata": {
        "id": "7_aiplY5vSDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transformer-based model"
      ],
      "metadata": {
        "id": "erIlhAL1otbf"
      }
    }
  ]
}